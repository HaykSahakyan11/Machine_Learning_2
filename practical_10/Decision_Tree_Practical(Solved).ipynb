{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data processing and visualization\n",
    "load winequality-white.csv dataset and make exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1;0.28;0.4;6.9;0.05;30;97;0.9951;3.26;0.44;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\n",
       "0   7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6                                                                                                                     \n",
       "1  6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9...                                                                                                                     \n",
       "2  8.1;0.28;0.4;6.9;0.05;30;97;0.9951;3.26;0.44;1...                                                                                                                     \n",
       "3  7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...                                                                                                                     \n",
       "4  7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4...                                                                                                                     "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality = pd.read_csv(\"winequality-white.csv\")\n",
    "wine_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_quality.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8      6.0  \n",
       "1      9.5      6.0  \n",
       "2     10.1      6.0  \n",
       "3      9.9      6.0  \n",
       "4      9.9      6.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = [] \n",
    "for i in list(wine_quality.index):\n",
    "    matrix.append([float(elem) for elem in wine_quality.iloc[i,0].split(\";\")])\n",
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "           'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "          'pH', 'sulphates', 'alcohol', 'quality']\n",
    "df = pd.DataFrame(data=matrix, index=list(wine_quality.index), columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = 'quality'\n",
    "df[target_col] = df[target_col].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['quality'])].copy()\n",
    "y = df['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision trees classification\n",
    "In this task we will try to predict wine quality based on its features by fitting a decision tree model. Fit a decision tree classifier by making a grid search over loss functions: 'giny', 'entropy' and over max_leaf_nodes parameter. Choose this parameters via 5-Fold cross-validation. Visualize the best model's tree diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(random_state=1),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                             13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                             22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                             31, ...]}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "hyper_params = [{'criterion' :  ['gini', 'entropy'],\n",
    "                 'max_leaf_nodes' : list(range(2, 100))}]\n",
    "\n",
    "# specify model\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params,\n",
    "                        cv = folds, \n",
    "                        refit = True,\n",
    "                        return_train_score=True)\n",
    "\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.5520711158026429 corresponding to hyperparameters {'criterion': 'gini', 'max_leaf_nodes': 74}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_score_id = model_cv.cv_results_['mean_test_score'].max(), model_cv.cv_results_['mean_test_score'].argmax()\n",
    "best_hyperparams = model_cv.cv_results_['params'][best_score_id]\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.5040816326530613\n",
      "accuracy_score:  0.5040816326530613\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini', max_leaf_nodes=50, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('f1_score: ', f1_score(y_test, y_pred, average='micro'))\n",
    "print('accuracy_score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'chlorides',\n",
       " 'citric acid',\n",
       " 'density',\n",
       " 'fixed acidity',\n",
       " 'free sulfur dioxide',\n",
       " 'pH',\n",
       " 'residual sugar',\n",
       " 'sulphates',\n",
       " 'total sulfur dioxide',\n",
       " 'volatile acidity']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing required packages for visualization\n",
    "from IPython.display import Image  \n",
    "from six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus, graphviz\n",
    "\n",
    "# Putting features\n",
    "features = list(X_train.loc[:, X_train.columns != 'quality'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the tree\n",
    "dot_data = StringIO()  \n",
    "export_graphviz(model, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.set_size(\"25,20!\") \n",
    "# graph.write_png('tree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison classification\n",
    "Try to predict wine quality with other classification tools that we studied(Logistic Regression, SVM, LDA) compare the accuracies and f-scores of all models on the test set and choose the best performing algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: {3, 4, 5, 6, 7, 8, 9}\n",
      "amount: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"labels:\", set(df.quality))\n",
    "print(\"amount:\", len(set(df.quality)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda f1_score:  0.5142857142857142\n",
      "lda accuracy_score:  0.5142857142857142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeLine = make_pipeline(LinearDiscriminantAnalysis(n_components=len(set(df.quality))-1), SVC(gamma = \"auto\", random_state=1))\n",
    "pipeLine.fit(X_train, y_train)\n",
    "svc = pipeLine.named_steps['svc']\n",
    "lda = pipeLine.named_steps['lineardiscriminantanalysis']\n",
    "lda_predict = lda.predict(X_test)\n",
    "print(\"lda f1_score: \", f1_score(y_test, lda_predict, average='micro'))\n",
    "print(\"lda accuracy_score: \", accuracy_score(y_test, lda_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END C=100, degree=2, gamma=0.1, kernel=sigmoid;, score=0.441 total time=   0.1s\n",
      "[CV 2/5] END C=100, degree=2, gamma=0.1, kernel=sigmoid;, score=0.425 total time=   0.2s\n",
      "[CV 3/5] END C=100, degree=2, gamma=0.1, kernel=sigmoid;, score=0.415 total time=   0.2s\n",
      "[CV 4/5] END C=100, degree=2, gamma=0.1, kernel=sigmoid;, score=0.390 total time=   0.1s\n",
      "[CV 5/5] END C=100, degree=2, gamma=0.1, kernel=sigmoid;, score=0.442 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, degree=3, gamma=0.1, kernel=sigmoid;, score=0.566 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, degree=3, gamma=0.1, kernel=sigmoid;, score=0.509 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, degree=3, gamma=0.1, kernel=sigmoid;, score=0.519 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, degree=3, gamma=0.1, kernel=sigmoid;, score=0.484 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, degree=3, gamma=0.1, kernel=sigmoid;, score=0.517 total time=   0.3s\n",
      "[CV 1/5] END C=1000, degree=1, gamma=0.0001, kernel=poly;, score=0.573 total time=   0.1s\n",
      "[CV 2/5] END C=1000, degree=1, gamma=0.0001, kernel=poly;, score=0.526 total time=   0.1s\n",
      "[CV 3/5] END C=1000, degree=1, gamma=0.0001, kernel=poly;, score=0.534 total time=   0.1s\n",
      "[CV 4/5] END C=1000, degree=1, gamma=0.0001, kernel=poly;, score=0.489 total time=   0.1s\n",
      "[CV 5/5] END C=1000, degree=1, gamma=0.0001, kernel=poly;, score=0.525 total time=   0.1s\n",
      "[CV 1/5] END C=1, degree=3, gamma=0.01, kernel=sigmoid;, score=0.577 total time=   0.3s\n",
      "[CV 2/5] END C=1, degree=3, gamma=0.01, kernel=sigmoid;, score=0.514 total time=   0.3s\n",
      "[CV 3/5] END C=1, degree=3, gamma=0.01, kernel=sigmoid;, score=0.520 total time=   0.3s\n",
      "[CV 4/5] END C=1, degree=3, gamma=0.01, kernel=sigmoid;, score=0.493 total time=   0.3s\n",
      "[CV 5/5] END C=1, degree=3, gamma=0.01, kernel=sigmoid;, score=0.524 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, degree=2, gamma=0.0001, kernel=sigmoid;, score=0.492 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, degree=2, gamma=0.0001, kernel=sigmoid;, score=0.445 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, degree=2, gamma=0.0001, kernel=sigmoid;, score=0.429 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, degree=2, gamma=0.0001, kernel=sigmoid;, score=0.434 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, degree=2, gamma=0.0001, kernel=sigmoid;, score=0.450 total time=   0.2s\n",
      "[CV 1/5] END C=10, degree=4, gamma=0.0001, kernel=rbf;, score=0.561 total time=   0.4s\n",
      "[CV 2/5] END C=10, degree=4, gamma=0.0001, kernel=rbf;, score=0.503 total time=   0.3s\n",
      "[CV 3/5] END C=10, degree=4, gamma=0.0001, kernel=rbf;, score=0.496 total time=   0.3s\n",
      "[CV 4/5] END C=10, degree=4, gamma=0.0001, kernel=rbf;, score=0.487 total time=   0.3s\n",
      "[CV 5/5] END C=10, degree=4, gamma=0.0001, kernel=rbf;, score=0.498 total time=   0.3s\n",
      "[CV 1/5] END C=100, degree=3, gamma=1, kernel=rbf;, score=0.548 total time=   0.6s\n",
      "[CV 2/5] END C=100, degree=3, gamma=1, kernel=rbf;, score=0.593 total time=   0.7s\n",
      "[CV 3/5] END C=100, degree=3, gamma=1, kernel=rbf;, score=0.573 total time=   0.7s\n",
      "[CV 4/5] END C=100, degree=3, gamma=1, kernel=rbf;, score=0.577 total time=   0.7s\n",
      "[CV 5/5] END C=100, degree=3, gamma=1, kernel=rbf;, score=0.610 total time=   0.7s\n",
      "[CV 1/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.574 total time=   0.3s\n",
      "[CV 2/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.532 total time=   0.3s\n",
      "[CV 3/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.528 total time=   0.3s\n",
      "[CV 4/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.493 total time=   0.3s\n",
      "[CV 5/5] END C=1, degree=2, gamma=0.01, kernel=rbf;, score=0.530 total time=   0.3s\n",
      "[CV 1/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.599 total time=   0.5s\n",
      "[CV 2/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.582 total time=   0.5s\n",
      "[CV 3/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.591 total time=   0.5s\n",
      "[CV 4/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.567 total time=   0.5s\n",
      "[CV 5/5] END C=1, degree=2, gamma=1, kernel=rbf;, score=0.590 total time=   0.4s\n",
      "[CV 1/5] END C=0.1, degree=4, gamma=0.01, kernel=rbf;, score=0.557 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, degree=4, gamma=0.01, kernel=rbf;, score=0.504 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, degree=4, gamma=0.01, kernel=rbf;, score=0.500 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, degree=4, gamma=0.01, kernel=rbf;, score=0.483 total time=   0.3s\n",
      "[CV 5/5] END C=0.1, degree=4, gamma=0.01, kernel=rbf;, score=0.499 total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=SVC(random_state=1),\n",
       "                   param_distributions={'C': [0.1, 1, 10, 100, 1000],\n",
       "                                        'degree': [1, 2, 3, 4],\n",
       "                                        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                                        'kernel': ['poly', 'rbf', 'sigmoid']},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "  \n",
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "    \n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "              'degree': [1, 2, 3, 4]}  \n",
    "  \n",
    "grid = RandomizedSearchCV(SVC(random_state = 1), param_grid, cv = folds, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(lda.transform(X_train), y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.5857543592149503 corresponding to hyperparameters {'kernel': 'rbf', 'gamma': 1, 'degree': 2, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_score_id = grid.cv_results_['mean_test_score'].max(),grid.cv_results_['mean_test_score'].argmax()\n",
    "best_hyperparams = grid.cv_results_['params'][best_score_id]\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc2 f1_score:  0.5459183673469388\n",
      "svc2 accuracy_score:  0.5459183673469388\n"
     ]
    }
   ],
   "source": [
    "# The degree is being ingnored with the 'rbf' kernel, so no need to specify it.\n",
    "svc2 = SVC(kernel='rbf', gamma=0.1, C=100, random_state=1)\n",
    "svc2.fit(lda.transform(X_train), y_train)\n",
    "svc2_predict = svc2.predict(lda.transform(X_test))\n",
    "print(\"svc2 f1_score: \", f1_score(y_test, svc2_predict, average='micro'))\n",
    "print(\"svc2 accuracy_score: \", accuracy_score(y_test, svc2_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END C=100, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.544, test=0.537) total time=   0.0s\n",
      "[CV 2/5] END C=100, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.548, test=0.526) total time=   0.0s\n",
      "[CV 3/5] END C=100, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.543, test=0.542) total time=   0.0s\n",
      "[CV 4/5] END C=100, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.541, test=0.548) total time=   0.0s\n",
      "[CV 5/5] END C=100, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.550, test=0.538) total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.544, test=0.537) total time=   0.0s\n",
      "[CV 2/5] END C=10, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.548, test=0.526) total time=   0.0s\n",
      "[CV 3/5] END C=10, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.543, test=0.542) total time=   0.0s\n",
      "[CV 4/5] END C=10, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.541, test=0.547) total time=   0.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.550, test=0.538) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.536, test=0.551) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.544, test=0.524) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.541, test=0.536) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.534, test=0.556) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.536, test=0.526) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.549, test=0.541) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.548, test=0.531) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.544, test=0.546) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.545, test=0.557) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.549, test=0.540) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.543, test=0.538) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.548, test=0.526) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.543, test=0.542) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.540, test=0.547) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.549, test=0.536) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.548, test=0.541) total time=   0.2s\n",
      "[CV 2/5] END C=1.0, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.548, test=0.531) total time=   0.3s\n",
      "[CV 3/5] END C=1.0, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.543, test=0.546) total time=   0.1s\n",
      "[CV 4/5] END C=1.0, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.546, test=0.557) total time=   0.4s\n",
      "[CV 5/5] END C=1.0, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.001;, score=(train=0.549, test=0.542) total time=   0.3s\n",
      "[CV 1/5] END C=10, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.548, test=0.541) total time=   1.4s\n",
      "[CV 2/5] END C=10, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.549, test=0.532) total time=   1.9s\n",
      "[CV 3/5] END C=10, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.543, test=0.546) total time=   1.9s\n",
      "[CV 4/5] END C=10, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.545, test=0.556) total time=   3.0s\n",
      "[CV 5/5] END C=10, l1_ratio=0.4, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.549, test=0.539) total time=   1.9s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.547, test=0.541) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.547, test=0.529) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.545, test=0.543) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.544, test=0.557) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.2, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.01;, score=(train=0.547, test=0.539) total time=   0.0s\n",
      "[CV 1/5] END C=10, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.548, test=0.541) total time=   1.5s\n",
      "[CV 2/5] END C=10, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.549, test=0.532) total time=   1.9s\n",
      "[CV 3/5] END C=10, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.543, test=0.546) total time=   1.8s\n",
      "[CV 4/5] END C=10, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.545, test=0.556) total time=   2.9s\n",
      "[CV 5/5] END C=10, l1_ratio=0.6, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.0001;, score=(train=0.549, test=0.539) total time=   1.8s\n",
      "[CV 1/5] END C=0.1, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.541, test=0.540) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.547, test=0.524) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.539, test=0.541) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.540, test=0.550) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, l1_ratio=0.8, multi_class=multinomial, penalty=elasticnet, solver=saga, tol=0.1;, score=(train=0.545, test=0.536) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=LogisticRegression(max_iter=10000, random_state=1),\n",
       "                   param_distributions=[{'C': [0.01, 0.1, 1.0, 10, 100],\n",
       "                                         'l1_ratio': [0.2, 0.4, 0.6, 0.8],\n",
       "                                         'multi_class': ['multinomial'],\n",
       "                                         'penalty': ['elasticnet'],\n",
       "                                         'solver': ['saga'],\n",
       "                                         'tol': [1e-05, 0.0001, 0.001, 0.01,\n",
       "                                                 0.1]}],\n",
       "                   return_train_score=True,\n",
       "                   scoring=make_scorer(f1_score, average=micro), verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [{'C' :  [0.01, 0.1, 1., 10, 100],\n",
    "                 'solver' : ['saga'],\n",
    "                 'penalty' : ['elasticnet'],\n",
    "                 'tol' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "                'l1_ratio': [0.2, 0.4, 0.6, 0.8],\n",
    "                'multi_class': ['multinomial']}]\n",
    "\n",
    "# specify model\n",
    "model = LogisticRegression(random_state=1, max_iter=10000)\n",
    "\n",
    "scorer = make_scorer(f1_score, average='micro')\n",
    "\n",
    "# set up GridSearchCV() \n",
    "model_cv = RandomizedSearchCV(estimator = model, \n",
    "                              param_distributions = hyper_params,\n",
    "                              scoring=scorer, \n",
    "                              cv = folds, \n",
    "                              verbose = 3,\n",
    "                              refit = True,\n",
    "                              return_train_score=True)\n",
    "\n",
    "model_cv.fit(lda.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.5431373315609769 corresponding to hyperparameters {'tol': 0.001, 'solver': 'saga', 'penalty': 'elasticnet', 'multi_class': 'multinomial', 'l1_ratio': 0.2, 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_score_id = model_cv.cv_results_['mean_test_score'].max(),model_cv.cv_results_['mean_test_score'].argmax()\n",
    "best_hyperparams = model_cv.cv_results_['params'][best_score_id]\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression f1_score:  0.513265306122449\n",
      "Logistic Regression accuracy_score:  0.513265306122449\n"
     ]
    }
   ],
   "source": [
    "# The degree is being ingnored with the 'rbf' kernel, so no need to specify it.\n",
    "lReg = LogisticRegression(C=0.1, l1_ratio=0.6, multi_class='multinomial', penalty='elasticnet',\n",
    "                          solver='saga', tol=1e-05, max_iter=1000, random_state=1)\n",
    "lReg.fit(lda.transform(X_train), y_train)\n",
    "lReg_predict = lReg.predict(lda.transform(X_test))\n",
    "print(\"Logistic Regression f1_score: \", f1_score(y_test, lReg_predict, average='micro'))\n",
    "print(\"Logistic Regression accuracy_score: \", accuracy_score(y_test, lReg_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision trees regression\n",
    "In this task we will use all the columns to predict alcohol concentration of a wine. Use the directives in task 1 as a guide to fit a Decision tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns.difference(['alcohol'])].copy()\n",
    "y = df['alcohol'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(random_state=1),\n",
       "             param_grid=[{'criterion': ['squared_error', 'friedman_mse',\n",
       "                                        'absolute_error'],\n",
       "                          'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                             13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                             22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                             31, ...]}],\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "hyper_params = [{'criterion' :  ['squared_error', 'friedman_mse', 'absolute_error'],\n",
    "                 'max_leaf_nodes' : list(range(2, 100))}]\n",
    "\n",
    "# specify model\n",
    "model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params,\n",
    "                        cv = folds, \n",
    "                        refit = True,\n",
    "                        return_train_score=True)\n",
    "\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.8352526232570983 corresponding to hyperparameters {'criterion': 'friedman_mse', 'max_leaf_nodes': 90}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_score_id = model_cv.cv_results_['mean_test_score'].max(),model_cv.cv_results_['mean_test_score'].argmax()\n",
    "best_hyperparams = model_cv.cv_results_['params'][best_score_id]\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(criterion='squared_error', max_leaf_nodes=99, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.3635662666326438\n",
      "MSE:  0.2406038233162766\n",
      "RMSE:  0.4905138360090127\n",
      "R^2:  0.847212724398044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print('MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R^2: ', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison regression\n",
    "Predict wine alcohol concentration with Linear Regression. Compare mean absolute errors and rooted mean squared errors. What is the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lReg2 = LinearRegression()\n",
    "lReg2.fit(X_train, y_train)\n",
    "lReg2_pred = lReg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.3003292527809054\n",
      "MSE:  0.1549733377565343\n",
      "RMSE:  0.39366653116125366\n",
      "R^2:  0.9015894521524802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print('MAE: ', mean_absolute_error(y_test, lReg2_pred))\n",
    "print('MSE: ', mean_squared_error(y_test, lReg2_pred))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, lReg2_pred)))\n",
    "print('R^2: ', r2_score(y_test, lReg2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The best model from DecisionTreeRegressor and Linear Regression is the last one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
